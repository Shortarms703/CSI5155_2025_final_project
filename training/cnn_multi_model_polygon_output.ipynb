{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "500f974ef0558d2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "52ef0c77068158b6",
   "metadata": {},
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import keras\n",
    "from keras import layers, models, Input\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import json\n",
    "\n",
    "print(keras.__version__)\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# noinspection PyUnresolvedReferences\n",
    "import pydiffvg\n",
    "\n",
    "print(\"done imports\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "66d9c9cb7cf0ed29",
   "metadata": {},
   "source": [
    "### Args"
   ]
  },
  {
   "cell_type": "code",
   "id": "671ee9dece76e3f4",
   "metadata": {},
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Model To train - Classifier or Polygon')\n",
    "\n",
    "parser.add_argument('--model', type=str, choices=['polygon', 'classifier'])\n",
    "parser.add_argument('--num-vertices', type=int,\n",
    "                    help='Number of vertices for polygon model training (required for polygon training)')\n",
    "parser.add_argument('--sbatch', type=bool, default=False, help='If running as sbatch job')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "if args.sbatch:\n",
    "    DEBUG = False\n",
    "    print()\n",
    "    print(\"Running in sbatch mode, setting DEBUG = False\")\n",
    "    print()\n",
    "else:\n",
    "    # FIXME THIS IS THE THING TO CHANGE FOR RUNNING LOCALLYish\n",
    "    args.model = 'polygon'\n",
    "    POLYGON_VERTICES = 3\n",
    "\n",
    "POLYGON_VERTICES = args.num_vertices\n",
    "\n",
    "if args.model == 'classifier':\n",
    "    try:\n",
    "        from tuning_v2.classifier_config import VERTEX_RANGE, BATCH_SIZE, NUM_EPOCHS, NUM_TRIALS, \\\n",
    "            CLASSIFIER_PARAMETER_GRID\n",
    "    except ModuleNotFoundError as e:\n",
    "        print(\"ModuleNotFoundError, assuming this is because the file is being run in a jupyter notebook.\")\n",
    "        os.chdir(os.path.dirname(os.getcwd()))\n",
    "        print(\"New working directory:\", os.getcwd())\n",
    "\n",
    "        from tuning_v2.classifier_config import VERTEX_RANGE, BATCH_SIZE, NUM_EPOCHS, NUM_TRIALS, \\\n",
    "            CLASSIFIER_PARAMETER_GRID\n",
    "\n",
    "        print(\"Import successful\")\n",
    "\n",
    "if args.model == 'polygon':\n",
    "    from tuning_v2.polygon_config import VERTEX_RANGE, BATCH_SIZE, NUM_EPOCHS, NUM_TRIALS, POLYGON_PARAMETER_GRID\n",
    "\n",
    "from tuning_v2.config import IMAGE_DIR, TUNING_RESULTS_FOLDER, CLASSIFIER_MODEL_SAVE_PATH, \\\n",
    "    POLYGON_MODEL_SAVE_PATH_LAMBDA, CONTINUE_LAST_RUN, VERBOSE, train_fraction, val_fraction, test_fraction, width, \\\n",
    "    height, DEBUG\n",
    "\n",
    "num_classes = VERTEX_RANGE[1] - VERTEX_RANGE[0] + 1\n",
    "\n",
    "if POLYGON_VERTICES is not None:\n",
    "    if POLYGON_VERTICES < VERTEX_RANGE[0] or POLYGON_VERTICES > VERTEX_RANGE[1]:\n",
    "        raise ValueError(f\"num_vertices ({POLYGON_VERTICES}) must be in range {VERTEX_RANGE}\")\n",
    "    print(f\"Polygon model training configured for {POLYGON_VERTICES} vertices\")\n",
    "elif args.model == 'polygon':\n",
    "    print(\"Note: --num-vertices not specified. Polygon training will require this argument.\")\n",
    "\n",
    "print(\"Current arguments:\")\n",
    "for arg in vars(args):\n",
    "    print(f\"  {arg}: {getattr(args, arg)}\")\n",
    "print(\"Batch size:\", BATCH_SIZE)\n",
    "print()\n",
    "\n",
    "SLURM_JOB_ID = os.environ.get('SLURM_JOB_ID', None)\n",
    "if SLURM_JOB_ID:\n",
    "    print(f\"SLURM Job ID: {SLURM_JOB_ID}\")\n",
    "else:\n",
    "    print(\"SLURM Job ID: Not available\")\n",
    "\n",
    "input_shape = (width, height, 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8b3ff6da0e8de3ad",
   "metadata": {},
   "source": [
    "def clear_cuda_cache():\n",
    "    try:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "            try:\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "            except:\n",
    "                pass\n",
    "            print(\"CUDA cache cleared successfully\")\n",
    "        else:\n",
    "            print(\"CUDA not available\")\n",
    "    except Exception as e:\n",
    "        print(f\"restart the kernel to continue\")\n",
    "        raise\n",
    "\n",
    "\n",
    "clear_cuda_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e0ee4ff01529751c",
   "metadata": {},
   "source": [
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "80dd60f3419b1b48",
   "metadata": {},
   "source": [
    "def rasterize(cmds, width, height):\n",
    "    if width != height:\n",
    "        raise Exception(\"Width and height must be the same\")\n",
    "\n",
    "    cmds = cmds * width\n",
    "\n",
    "    polygon = pydiffvg.Polygon(points=cmds, is_closed=True)\n",
    "    shapes = [polygon]\n",
    "\n",
    "    shape_group = pydiffvg.ShapeGroup(\n",
    "        shape_ids=torch.tensor([0]),\n",
    "        fill_color=torch.tensor([0, 0, 0, 1.0])\n",
    "    )\n",
    "    shape_groups = [shape_group]\n",
    "\n",
    "    scene_args = pydiffvg.RenderFunction.serialize_scene(\n",
    "        width, height, shapes, shape_groups\n",
    "    )\n",
    "\n",
    "    background = torch.ones(width, height, 4, device=pydiffvg.get_device())\n",
    "\n",
    "    render = pydiffvg.RenderFunction.apply\n",
    "    img = render(width, height, 2, 2, 0, background, *scene_args)\n",
    "\n",
    "    img_gray = img[:, :, :3].mean(dim=2, keepdim=True)\n",
    "\n",
    "    return img_gray"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a6ddfdd1eb33495",
   "metadata": {},
   "source": [
    "### Classifier Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "id": "3a2a6233c068de08",
   "metadata": {},
   "source": [
    "def create_cls_model(input_shape, num_classes, conv_filters=[16, 32, 64], dense_units=64, dropout_rate=0.0,\n",
    "                     activation='relu'):\n",
    "    raise NotImplementedError\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    # CNN layers\n",
    "    for filters in conv_filters:\n",
    "        x = layers.Conv2D(filters, 3, activation=activation)(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        if dropout_rate > 0.0:\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Flatten and dense layers\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(dense_units, activation=activation)(x)\n",
    "    if dropout_rate > 0.0:\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Output layer\n",
    "    class_outputs = layers.Dense(num_classes, activation='softmax', name='class')(x)\n",
    "\n",
    "    model = models.Model(inputs, class_outputs)\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df315e0441247c2e",
   "metadata": {},
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ClassifierCNN(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes, conv_filters=[16, 32, 64],\n",
    "                 dense_units=64, dropout2d_rate_CNN=0.0, dropout_rate_FFN=0.0, activation='relu', batch_norm=False):\n",
    "        super().__init__()\n",
    "\n",
    "        H, W, C = input_shape\n",
    "        in_channels = C\n",
    "\n",
    "        act = getattr(F, activation)\n",
    "\n",
    "        layers_list = []\n",
    "        current_channels = in_channels\n",
    "        for f in conv_filters:\n",
    "            layers_list.append(nn.Conv2d(current_channels, f, kernel_size=3, padding=1))\n",
    "            if batch_norm:\n",
    "                layers_list.append(nn.BatchNorm2d(f))\n",
    "            layers_list.append(nn.ReLU() if activation == \"relu\" else nn.SiLU())\n",
    "            layers_list.append(nn.MaxPool2d(2))\n",
    "            if dropout2d_rate_CNN > 0:\n",
    "                layers_list.append(nn.Dropout2d(dropout2d_rate_CNN))\n",
    "            current_channels = f\n",
    "\n",
    "        self.conv = nn.Sequential(*layers_list)\n",
    "\n",
    "        # compute output size\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, H, W)\n",
    "            conv_out = self.conv(dummy).shape\n",
    "            conv_flat = conv_out[1] * conv_out[2] * conv_out[3]\n",
    "\n",
    "        self.fc1 = nn.Linear(conv_flat, dense_units)\n",
    "        self.dropout = nn.Dropout(dropout_rate_FFN) if dropout_rate_FFN > 0 else nn.Identity()\n",
    "        self.out = nn.Linear(dense_units, num_classes)\n",
    "\n",
    "        self.activation = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convert NHWC → NCHW\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.out(x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c2040077d773b870",
   "metadata": {},
   "source": [
    "### Polygon Model Definition"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PolygonCNN(nn.Module):\n",
    "    def __init__(self, input_shape, num_vertices, conv_filters=[16, 32, 64], dense_units=64, dropout_rate=0.0,\n",
    "                 activation='relu'):\n",
    "        super().__init__()\n",
    "\n",
    "        H, W, C = input_shape\n",
    "        in_channels = C\n",
    "\n",
    "        act = getattr(F, activation)\n",
    "\n",
    "        layers_list = []\n",
    "        current_channels = in_channels\n",
    "        for f in conv_filters:\n",
    "            layers_list.append(nn.Conv2d(current_channels, f, kernel_size=3, padding=1))\n",
    "            # if batch_norm:\n",
    "            #     layers_list.append(nn.BatchNorm2d(f))\n",
    "            layers_list.append(nn.ReLU() if activation == \"relu\" else nn.SiLU())\n",
    "            layers_list.append(nn.MaxPool2d(2))\n",
    "            # if dropout2d_rate_CNN > 0:\n",
    "            #     layers_list.append(nn.Dropout2d(dropout2d_rate_CNN))\n",
    "            current_channels = f\n",
    "\n",
    "        self.conv = nn.Sequential(*layers_list)\n",
    "\n",
    "        # compute flattened conv output size\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, H, W)\n",
    "            conv_out = self.conv(dummy).shape\n",
    "            conv_flat = conv_out[1] * conv_out[2] * conv_out[3]\n",
    "\n",
    "        self.fc1 = nn.Linear(conv_flat, dense_units)\n",
    "        self.dropout = nn.Dropout(dropout_rate) if dropout_rate > 0 else nn.Identity()\n",
    "\n",
    "        # output: num_vertices * 2 coordinates\n",
    "        self.out = nn.Linear(dense_units, num_vertices * 2)\n",
    "\n",
    "        self.num_vertices = num_vertices\n",
    "        self.activation = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        # NHWC → NCHW\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # raw linear → reshape → sigmoid\n",
    "        coords = self.out(x)\n",
    "        coords = coords.view(-1, self.num_vertices, 2)\n",
    "        coords = torch.sigmoid(coords)\n",
    "\n",
    "        return coords\n"
   ],
   "id": "61d37620fef078c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8778c8815396ee54",
   "metadata": {},
   "source": [
    "def create_poly_model(input_shape, num_vertices, conv_filters=[16, 32, 64], dense_units=64, dropout_rate=0.0,\n",
    "                      activation='relu'):\n",
    "    set_seeds()\n",
    "    model = PolygonCNN(input_shape, num_vertices, conv_filters, dense_units, dropout_rate, activation)\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a596349387674d7d",
   "metadata": {},
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, width, height, vertex_range=None):\n",
    "        all_paths = glob.glob(os.path.join(image_dir, \"polygon_*\", \"*.png\"))\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.vertex_range = vertex_range\n",
    "\n",
    "        self.class_ids = []\n",
    "\n",
    "        for path in all_paths:\n",
    "            fname = os.path.basename(path)\n",
    "            match = re.search(r\"polygon_(\\d+)_\", fname)\n",
    "            if match:\n",
    "                vertex_count = int(match.group(1))\n",
    "\n",
    "                # normalize label to 0-based index if vertex_range is provided\n",
    "                if vertex_range is not None:\n",
    "                    if not (vertex_range[0] <= vertex_count <= vertex_range[1]):\n",
    "                        continue  # skip this image completely\n",
    "\n",
    "                    normalized = vertex_count - vertex_range[0]\n",
    "                    self.image_paths.append(path)\n",
    "                    self.class_ids.append(normalized)\n",
    "            else:\n",
    "                raise ValueError(f\"Filename {fname} doesn't match pattern polygon_<class>_*.png\")\n",
    "\n",
    "        print(f\"Found {len(self.image_paths)} images in {image_dir} within vertex range {vertex_range}\")\n",
    "\n",
    "        if len(self.class_ids) > 0:\n",
    "            min_label = min(self.class_ids)\n",
    "            max_label = max(self.class_ids)\n",
    "            print(f\"Label range: [{min_label}, {max_label}], unique labels: {sorted(set(self.class_ids))}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\").resize((self.width, self.height))\n",
    "\n",
    "        img_np = np.array(img).astype(np.float32) / 255.0\n",
    "\n",
    "        img_np = np.expand_dims(img_np, axis=-1)\n",
    "\n",
    "        img_tensor = torch.tensor(img_np, dtype=torch.float32)\n",
    "        img_label = torch.tensor(self.class_ids[idx], dtype=torch.long)\n",
    "\n",
    "        return img_tensor, img_label"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14984aee613b21b9",
   "metadata": {},
   "source": [
    "def cls_validate_labels(label_batch, num_classes):\n",
    "    if label_batch.min() < 0 or label_batch.max() >= num_classes:\n",
    "        raise ValueError(\n",
    "            f\"Labels out of range: min={label_batch.min().item()}, max={label_batch.max().item()}, num_classes={num_classes}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d6b0ef451842aeaf",
   "metadata": {},
   "source": [
    "def cls_train_step(model, img_batch, label_batch, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    pred_batch = model(img_batch)\n",
    "\n",
    "    if not isinstance(label_batch, torch.LongTensor):\n",
    "        label_batch = label_batch.long()\n",
    "\n",
    "    num_classes = pred_batch.shape[1]\n",
    "    cls_validate_labels(label_batch, num_classes)\n",
    "\n",
    "    loss = torch.nn.functional.cross_entropy(pred_batch, label_batch)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "76ec2edfb9511ff4",
   "metadata": {},
   "source": [
    "def get_cls_val_loss(model, val_loader):\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_batch, label_batch in val_loader:\n",
    "            val_batch = val_batch.to(device)\n",
    "            if not isinstance(label_batch, torch.LongTensor):\n",
    "                label_batch = label_batch.long()\n",
    "            label_batch = label_batch.to(device)\n",
    "\n",
    "            pred_batch = model(val_batch)\n",
    "\n",
    "            num_classes = pred_batch.shape[1]\n",
    "            cls_validate_labels(label_batch, num_classes)\n",
    "\n",
    "            loss = torch.nn.functional.cross_entropy(pred_batch, label_batch)\n",
    "            val_loss += loss\n",
    "\n",
    "    return val_loss"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a82562c2d18cef16",
   "metadata": {},
   "source": [
    "def poly_train_step(model, target_img_batch, width, height, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    coord_pred_batch = model(target_img_batch)\n",
    "\n",
    "    batch_loss = 0.0\n",
    "    batch_size = target_img_batch.shape[0]\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        target_img = target_img_batch[i]  # Shape (H, W, 1)\n",
    "        coord_pred = coord_pred_batch[i]  # Shape (num_commands, 2)\n",
    "\n",
    "        pred_img = rasterize(coord_pred, width=width, height=height)\n",
    "        loss = torch.mean((pred_img - target_img) ** 2)\n",
    "        batch_loss += loss\n",
    "\n",
    "    avg_loss = batch_loss / batch_size\n",
    "\n",
    "    # Backprop\n",
    "    optimizer.zero_grad()\n",
    "    avg_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return avg_loss.item()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9bf1e97792fa2b6",
   "metadata": {},
   "source": [
    "def get_poly_val_loss(model, val_loader, width, height):\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_batch, _ in val_loader:  # DataLoader returns (img, label) tuples\n",
    "            val_batch = val_batch.to(device)\n",
    "            coord_pred_batch = model(val_batch)\n",
    "            batch_size = val_batch.shape[0]\n",
    "            batch_loss = 0.0\n",
    "            for i in range(batch_size):\n",
    "                target_img = val_batch[i]\n",
    "                coord_pred = coord_pred_batch[i]\n",
    "                pred_img = rasterize(coord_pred, width=width, height=height)\n",
    "                loss = torch.mean((pred_img - target_img) ** 2)\n",
    "                batch_loss += loss\n",
    "\n",
    "            val_loss += batch_loss / batch_size\n",
    "    return val_loss"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "10768cb374120696",
   "metadata": {},
   "source": [
    "pydiffvg.set_use_gpu(torch.cuda.is_available())\n",
    "device = pydiffvg.get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "dataset = ImageDataset(IMAGE_DIR, width, height, vertex_range=VERTEX_RANGE)\n",
    "if len(dataset) == 0:\n",
    "    raise Exception(\"No images found in \" + IMAGE_DIR)\n",
    "\n",
    "train_dataset, val_test_dataset = keras.utils.split_dataset(\n",
    "    dataset, train_fraction, val_fraction + test_fraction, shuffle=True, seed=42\n",
    ")\n",
    "\n",
    "val_dataset, test_dataset = keras.utils.split_dataset(\n",
    "    val_test_dataset, val_fraction / (val_fraction + test_fraction), test_fraction / (val_fraction + test_fraction),\n",
    "    shuffle=True, seed=42\n",
    ")\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = 42 + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    worker_init_fn=seed_worker\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    worker_init_fn=seed_worker\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    worker_init_fn=seed_worker\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "222c945b97951d4b",
   "metadata": {},
   "source": [
    "### Classifier Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c83c3c18c68269",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "id": "58ca8d64e4b7d6e",
   "metadata": {},
   "source": [
    "def train_classifier_model(train_loader, cls_model, num_epochs, learning_rate, weight_decay, patience, verbose=False):\n",
    "    optimizer = torch.optim.Adam(cls_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    print(\"Starting Classifier Model training...\")\n",
    "    training_start = time.time()\n",
    "\n",
    "    training_loss_history = []\n",
    "    validation_loss_history = []\n",
    "    training_accuracy_history = []\n",
    "    validation_accuracy_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose:\n",
    "            print(f\"--- Epoch {epoch + 1}/{num_epochs} ---\")\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        if len(train_loader) == 0:\n",
    "            raise Exception(\"No images found in train loader\")\n",
    "\n",
    "        for target_batch, label_batch in train_loader:\n",
    "            target_batch = target_batch.to(device)\n",
    "            if not isinstance(label_batch, torch.LongTensor):\n",
    "                label_batch = label_batch.long()\n",
    "            label_batch = label_batch.to(device)\n",
    "\n",
    "            loss = cls_train_step(cls_model, target_batch, label_batch, optimizer)\n",
    "            epoch_loss += loss\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        training_loss_history.append(avg_epoch_loss)\n",
    "\n",
    "        val_loss = get_cls_val_loss(cls_model, val_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        validation_loss_history.append(avg_val_loss.item())\n",
    "\n",
    "        training_accuracy = 0.0\n",
    "        validation_accuracy = 0.0\n",
    "        for img_batch, label_batch in train_loader:\n",
    "            img_batch = img_batch.to(device)\n",
    "            if not isinstance(label_batch, torch.LongTensor):\n",
    "                label_batch = label_batch.long()\n",
    "            label_batch = label_batch.to(device)\n",
    "\n",
    "            pred_batch = cls_model(img_batch)\n",
    "            _, predicted = torch.max(pred_batch, 1)\n",
    "            training_accuracy += (predicted == label_batch).sum().item()\n",
    "        for img_batch, label_batch in val_loader:\n",
    "            img_batch = img_batch.to(device)\n",
    "            if not isinstance(label_batch, torch.LongTensor):\n",
    "                label_batch = label_batch.long()\n",
    "            label_batch = label_batch.to(device)\n",
    "\n",
    "            pred_batch = cls_model(img_batch)\n",
    "            _, predicted = torch.max(pred_batch, 1)\n",
    "            validation_accuracy += (predicted == label_batch).sum().item()\n",
    "\n",
    "        training_accuracy /= len(train_loader.dataset)\n",
    "        validation_accuracy /= len(val_loader.dataset)\n",
    "        training_accuracy_history.append(training_accuracy)\n",
    "        validation_accuracy_history.append(validation_accuracy)\n",
    "\n",
    "        best_val_loss_epoch = validation_loss_history.index(min(validation_loss_history))\n",
    "        epoch_since_min_val_loss = epoch - best_val_loss_epoch\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Training Loss: {avg_epoch_loss:.6f} -\",\n",
    "                  f\"Validation Loss: {avg_val_loss:.6f} -\\n\",\n",
    "                  f\"Training Accuracy: {(training_accuracy * 100):.4f} -\",\n",
    "                  f\"Validation Accuracy: {(validation_accuracy * 100):.4f} -\",\n",
    "                  f\"Time taken {round(time.time() - epoch_start, 2)} -\",\n",
    "                  f\"Epochs since min val loss: {epoch_since_min_val_loss}\")\n",
    "\n",
    "        if epoch_since_min_val_loss > patience:\n",
    "            print()\n",
    "            print(f\"No validation loss improvement since {best_val_loss_epoch}, stopping training\")\n",
    "            break\n",
    "\n",
    "    clear_cuda_cache()\n",
    "\n",
    "    print(\"Training complete, took \" + str(round(time.time() - training_start, 2)))\n",
    "\n",
    "    return training_loss_history, validation_loss_history, training_accuracy_history, validation_accuracy_history"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "69dcdad7ac486b4a",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "id": "a3c595430668d986",
   "metadata": {},
   "source": [
    "def hp_tuning_trial(input_shape, num_classes, num_epochs, trial, verbose):\n",
    "    model = ClassifierCNN(input_shape,\n",
    "                          num_classes,\n",
    "                          conv_filters=trial[\"conv_filters\"],\n",
    "                          dense_units=trial[\"dense_units\"],\n",
    "                          dropout_rate_FFN=trial[\"dropout_rate\"],\n",
    "                          activation=trial[\"activation\"]\n",
    "                          )\n",
    "    model.to(device)\n",
    "    try:\n",
    "        training_loss_history, validation_loss_history, training_accuracy_history, validation_accuracy_history = train_classifier_model(\n",
    "            train_loader,\n",
    "            model,\n",
    "            num_epochs=num_epochs,\n",
    "            learning_rate=trial[\"learning_rate\"],\n",
    "            weight_decay=trial[\"weight_decay\"],\n",
    "            patience=trial[\"patience\"],\n",
    "            verbose=verbose,\n",
    "        )\n",
    "    finally:\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        clear_cuda_cache()\n",
    "\n",
    "    return validation_loss_history"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "677b012ce5457c80",
   "metadata": {},
   "source": [
    "def print_gpu_memory():\n",
    "    \"\"\"Print current GPU memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024 ** 3  # GB\n",
    "        reserved = torch.cuda.memory_reserved() / 1024 ** 3  # GB\n",
    "        max_allocated = torch.cuda.max_memory_allocated() / 1024 ** 3  # GB\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB, Max: {max_allocated:.2f} GB\")\n",
    "        torch.cuda.reset_peak_memory_stats()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ad66c63b1e26c573",
   "metadata": {},
   "source": [
    "def run_classifier_hp_tuning(tuning_results_folder, parameter_grid, num_epochs, verbose):\n",
    "    input_shape = (width, height, 1)\n",
    "    classifier_tuning_results_folder = os.path.join(tuning_results_folder, 'classifier')\n",
    "\n",
    "    initial_trial_index = 0\n",
    "\n",
    "    if CONTINUE_LAST_RUN:\n",
    "        # look in the folder, and find the most recent file\n",
    "        results_files = glob.glob(\n",
    "            os.path.join(classifier_tuning_results_folder, \"time_classifier_hp_tuning_results_*.json\"))\n",
    "        if len(results_files) != 0:\n",
    "            results_file = os.path.basename(max(results_files, key=os.path.getctime))\n",
    "            with open(os.path.join(classifier_tuning_results_folder, results_file), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                completed_trials = data['meta'][\"completed_trials\"]\n",
    "                total_trials = data['meta'][\"total_trials\"]\n",
    "\n",
    "                if completed_trials >= total_trials:\n",
    "                    print(f\"All {total_trials} trials already completed in {results_file}. Starting new tuning run.\")\n",
    "                elif total_trials != NUM_TRIALS:\n",
    "                    print(\n",
    "                        f\"Warning: Mismatch in total trials. Previous run had {total_trials} trials, current run has {NUM_TRIALS} trials. Starting new tuning run.\")\n",
    "                else:\n",
    "                    initial_trial_index = completed_trials\n",
    "                    print(f\"Continuing from last run, starting with trial_index = {initial_trial_index}\")\n",
    "\n",
    "    for trial_index in range(initial_trial_index, NUM_TRIALS):\n",
    "        print(f\"\\n=== Hyperparameter Tuning Trial {trial_index + 1}/{NUM_TRIALS} ===\")\n",
    "\n",
    "        if trial_index == 0:\n",
    "            job_id_suffix = f\"job{SLURM_JOB_ID}_\" if SLURM_JOB_ID else \"\"\n",
    "            results_file = \"time_classifier_hp_tuning_results_\" + job_id_suffix + time.strftime(\n",
    "                \"%Y%m%d-%H%M%S\") + \".json\"\n",
    "            data = {\n",
    "                \"meta\": {\n",
    "                    \"total_trials\": NUM_TRIALS,\n",
    "                    \"completed_trials\": 0\n",
    "                },\n",
    "                \"results\": []\n",
    "            }\n",
    "            with open(os.path.join(classifier_tuning_results_folder, results_file), 'w') as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "        else:\n",
    "            # look in the folder, and find the most recent file\n",
    "            results_files = glob.glob(\n",
    "                os.path.join(classifier_tuning_results_folder, \"time_classifier_hp_tuning_results_*.json\"))\n",
    "            if len(results_files) == 0:\n",
    "                raise Exception(\n",
    "                    \"No results file found in \" + classifier_tuning_results_folder + \". Expected one from trial 0.\")\n",
    "            results_file = os.path.basename(max(results_files, key=os.path.getctime))\n",
    "\n",
    "        # randomly sample hyperparameters from parameter grid\n",
    "        trial = {\n",
    "            'learning_rate': random.choice(parameter_grid['learning_rate']),\n",
    "            'conv_filters': random.choice(parameter_grid['conv_filters']),\n",
    "            'dense_units': random.choice(parameter_grid['dense_units']),\n",
    "            'dropout_rate': random.choice(parameter_grid['dropout_rate']),\n",
    "            'activation': random.choice(parameter_grid['activation']),\n",
    "            'weight_decay': random.choice(parameter_grid['weight_decay']),\n",
    "            'patience': random.choice(parameter_grid['patience']),\n",
    "        }\n",
    "        print(f\"Trial {trial_index + 1} hyperparameters: {trial}\")\n",
    "\n",
    "        val_loss_history = hp_tuning_trial(input_shape, num_classes, num_epochs, trial, verbose)\n",
    "\n",
    "        best_val_loss = min(val_loss_history)\n",
    "        best_val_loss_epoch = val_loss_history.index(best_val_loss) + 1\n",
    "\n",
    "        with open(os.path.join(classifier_tuning_results_folder, results_file), 'r+') as f:\n",
    "            data = json.load(f)\n",
    "            data[\"meta\"][\"completed_trials\"] = trial_index + 1\n",
    "            data[\"results\"].append({\n",
    "                'trial_index': trial_index + 1,\n",
    "                'hyperparameters': trial,\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_epoch': best_val_loss_epoch,\n",
    "            })\n",
    "            f.seek(0)\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "        print(f\"Trial {trial_index + 1} best validation loss: {best_val_loss:.6f} at epoch {best_val_loss_epoch}\")\n",
    "\n",
    "        print_gpu_memory()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d214d7e32f06395",
   "metadata": {},
   "source": [
    "if args.model == 'classifier':\n",
    "    run_classifier_hp_tuning(TUNING_RESULTS_FOLDER, CLASSIFIER_PARAMETER_GRID, NUM_EPOCHS, VERBOSE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "282fb7af580cb907",
   "metadata": {},
   "source": [
    "#### Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da52371def5d94",
   "metadata": {},
   "source": [
    "#### Train Classifier with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "id": "bde42a15d7b805b6",
   "metadata": {},
   "source": [
    "if args.model == 'classifier':\n",
    "    input_shape = (width, height, 1)\n",
    "    # find json file with tuning results, most recent that is completed\n",
    "    results_files = glob.glob(\n",
    "        os.path.join(TUNING_RESULTS_FOLDER, 'classifier', \"time_classifier_hp_tuning_results_*.json\"))\n",
    "    if len(results_files) == 0:\n",
    "        raise Exception(\"No tuning results file found in \" + os.path.join(TUNING_RESULTS_FOLDER, 'classifier'))\n",
    "\n",
    "    results_file = os.path.basename(max(results_files, key=os.path.getctime))\n",
    "    print(f\"Results file found: {results_file}\")\n",
    "\n",
    "    best_hyperparameters = best_epoch = None\n",
    "    with open(os.path.join(TUNING_RESULTS_FOLDER, 'classifier', results_file), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        completed_trials = data['meta'][\"completed_trials\"]\n",
    "        total_trials = data['meta'][\"total_trials\"]\n",
    "        if completed_trials < total_trials:\n",
    "            print(\n",
    "                f\"Warning: Tuning run in {results_file} not complete. Completed {completed_trials}/{total_trials} trials. Please complete tuning or delete incomplete tuning file\")\n",
    "\n",
    "        results = data['results']\n",
    "        best_trial = sorted(results, key=lambda x: x['best_val_loss'])[0]\n",
    "        best_hyperparameters = best_trial['hyperparameters']\n",
    "        best_epoch = best_trial['best_epoch']\n",
    "\n",
    "    if best_hyperparameters is None or best_epoch is None:\n",
    "        raise Exception(\"Could not find best hyperparameters or best epoch in \" + results_file)\n",
    "\n",
    "    print(f\"Best hyperparameters from tuning in {results_file}:\")\n",
    "    for k, v in best_hyperparameters.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    print(f\"Best epoch from tuning: {best_epoch}\")\n",
    "\n",
    "    set_seeds()\n",
    "    cls_model = ClassifierCNN(input_shape,\n",
    "                              num_classes,\n",
    "                              conv_filters=best_hyperparameters['conv_filters'],\n",
    "                              dense_units=best_hyperparameters['dense_units'],\n",
    "                              dropout_rate_FFN=best_hyperparameters['dropout_rate'],\n",
    "                              activation=best_hyperparameters['activation']\n",
    "                              )\n",
    "\n",
    "    cls_model.to(device)\n",
    "\n",
    "    training_loss_history, validation_loss_history, training_accuracy_history, validation_accuracy_history = train_classifier_model(\n",
    "        train_loader,\n",
    "        cls_model,\n",
    "        num_epochs=best_trial[\"best_epoch\"],\n",
    "        learning_rate=best_hyperparameters['learning_rate'],\n",
    "        weight_decay=best_hyperparameters['weight_decay'],\n",
    "        patience=best_hyperparameters['patience'],\n",
    "        verbose=True\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "85642db57ba5e6da",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "id": "20bd1e5cffebb347",
   "metadata": {},
   "source": [
    "if args.model == 'classifier':\n",
    "    # timestamp model path\n",
    "    os.makedirs(os.path.dirname(CLASSIFIER_MODEL_SAVE_PATH), exist_ok=True)\n",
    "\n",
    "    torch.save({\n",
    "        \"model_state\": cls_model.state_dict(),\n",
    "        \"hyperparameters\": best_hyperparameters,\n",
    "        \"best_epoch\": best_epoch,\n",
    "    }, CLASSIFIER_MODEL_SAVE_PATH)\n",
    "\n",
    "    print(f\"Saved model to {CLASSIFIER_MODEL_SAVE_PATH}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "397310b73bca392a",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "id": "3580b79cffe04149",
   "metadata": {},
   "source": [
    "if args.model == 'classifier':\n",
    "    loaded = torch.load(CLASSIFIER_MODEL_SAVE_PATH, map_location=device)\n",
    "\n",
    "    loaded_hparams = loaded[\"hyperparameters\"]\n",
    "\n",
    "    try:\n",
    "        set_seeds()\n",
    "        model_loaded = ClassifierCNN(input_shape,\n",
    "                                     num_classes,\n",
    "                                     conv_filters=loaded_hparams[\"conv_filters\"],\n",
    "                                     dense_units=loaded_hparams[\"dense_units\"],\n",
    "                                     dropout_rate_FFN=loaded_hparams[\"dropout_rate\"],\n",
    "                                     activation=loaded_hparams[\"activation\"],\n",
    "                                     )\n",
    "\n",
    "        model_loaded.load_state_dict(loaded[\"model_state\"])\n",
    "        model_loaded.to(device)\n",
    "        model_loaded.eval()\n",
    "\n",
    "        print(\"Model loaded and ready.\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error loading model\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a66f76ab195c2ce7",
   "metadata": {},
   "source": [
    "#### Evaluate Classifier on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "id": "26ce106ce5a8df9f",
   "metadata": {},
   "source": [
    "if DEBUG:\n",
    "    print_gpu_memory()\n",
    "    clear_cuda_cache()\n",
    "    print(torch.cuda.memory_allocated(), torch.cuda.memory_reserved())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "75a3379555c2b990",
   "metadata": {},
   "source": [
    "# TRYING TO FIX CLASSIFIER MODEL\n",
    "\n",
    "if DEBUG and args.model == 'classifier':\n",
    "    best_hyperparameters = {\n",
    "        'learning_rate': 0.0001,\n",
    "        'weight_decay': 0.00005,\n",
    "        'batch_norm': True,\n",
    "        'conv_filters': [32, 48, 48, 64],\n",
    "        'dense_units': 64,\n",
    "        'dropout2d_rate_CNN': 0.1,\n",
    "        'dropout_rate_FFN': 0.5,\n",
    "        'activation': 'relu',\n",
    "        'patience': 25\n",
    "    }\n",
    "    best_epoch = 177"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "139784e804e8a723",
   "metadata": {},
   "source": [
    "if DEBUG and args.model == 'classifier':\n",
    "    set_seeds()\n",
    "    cls_model = ClassifierCNN(input_shape,\n",
    "                              num_classes,\n",
    "                              conv_filters=best_hyperparameters[\"conv_filters\"],\n",
    "                              dense_units=best_hyperparameters[\"dense_units\"],\n",
    "                              dropout2d_rate_CNN=best_hyperparameters[\"dropout2d_rate_CNN\"],\n",
    "                              dropout_rate_FFN=best_hyperparameters[\"dropout_rate_FFN\"],\n",
    "                              activation=best_hyperparameters[\"activation\"],\n",
    "                              batch_norm=best_hyperparameters[\"batch_norm\"]\n",
    "                              )\n",
    "\n",
    "    cls_model.to(device)\n",
    "    training_loss_history, validation_loss_history, training_accuracy_history, validation_accuracy_history = train_classifier_model(\n",
    "        train_loader,\n",
    "        cls_model,\n",
    "        num_epochs=best_epoch,\n",
    "        learning_rate=best_hyperparameters['learning_rate'],\n",
    "        weight_decay=best_hyperparameters[\"weight_decay\"],\n",
    "        patience=best_hyperparameters[\"patience\"],\n",
    "        verbose=True\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90e2f94a0bf52cc",
   "metadata": {},
   "source": [
    "if DEBUG and args.model == 'classifier':\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    ax1.plot(training_loss_history, label='Train Loss', linestyle='--')\n",
    "    ax1.plot(validation_loss_history, label='Validation Loss', linestyle='--')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlim(0, 200)\n",
    "    ax1.set_ylim(0, 2)\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(training_accuracy_history, label='Train Accuracy')\n",
    "    ax2.plot(validation_accuracy_history, label='Validation Accuracy')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_ylim(0, 1)\n",
    "\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper left')\n",
    "\n",
    "    plt.title('Training and Validation Loss/Accuracy Over Epochs')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(\"plot_data/classifier_training_history_plot.svg\", format=\"svg\")\n",
    "    fig.savefig(\"plot_data/classifier_training_history_plot.pdf\", format=\"pdf\")\n",
    "    fig.savefig(\"plot_data/classifier_training_history_plot.png\", format=\"png\")\n",
    "\n",
    "    print(\"best_hyperparameters:\")\n",
    "    for k, v in best_hyperparameters.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print()\n",
    "    print(\"Final validation accuracy:\", validation_accuracy_history[-1])\n",
    "    print(\"Best validation accuracy:\", max(validation_accuracy_history),\n",
    "          \"occurred at epoch\",\n",
    "          validation_accuracy_history.index(max(validation_accuracy_history)))\n",
    "\n",
    "    output = {\n",
    "        \"training_loss\": training_loss_history,\n",
    "        \"validation_loss\": validation_loss_history,\n",
    "        \"training_accuracy\": training_accuracy_history,\n",
    "        \"validation_accuracy\": validation_accuracy_history,\n",
    "    }\n",
    "\n",
    "    os.makedirs(\"plot_data\", exist_ok=True)\n",
    "    json_path = os.path.join(\"plot_data\", \"classifier_training_curves.json\")\n",
    "\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(output, f, indent=4)\n",
    "\n",
    "    print(\"Saved plot data to:\", json_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8446e59c537b51de",
   "metadata": {},
   "source": [
    "if args.model == 'classifier':\n",
    "    cls_model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    print(\"Evaluating classifier model on test set...\")\n",
    "    with torch.no_grad():\n",
    "        for img_batch, label_batch in test_loader:\n",
    "            img_batch = img_batch.to(device)\n",
    "            if not isinstance(label_batch, torch.LongTensor):\n",
    "                label_batch = label_batch.long()\n",
    "            label_batch = label_batch.to(device)\n",
    "\n",
    "            pred_batch = cls_model(img_batch)\n",
    "\n",
    "            loss = torch.nn.functional.cross_entropy(pred_batch, label_batch)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(pred_batch, 1)\n",
    "\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(label_batch.cpu().numpy())\n",
    "\n",
    "            total += label_batch.size(0)\n",
    "            correct += (predicted == label_batch).sum().item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"Classifier Test Set Evaluation Results\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    print(f\"Average Test Loss: {avg_test_loss:.6f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}% ({correct}/{total})\")\n",
    "    print(f\"{'=' * 50}\\n\")\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    class_names = [f\"{i + VERTEX_RANGE[0]} vertices\" for i in range(num_classes)]\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix - Classifier Test Set')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_predictions,\n",
    "                                target_names=class_names, digits=4))\n",
    "\n",
    "    print(\"\\nPer-Class Accuracy:\")\n",
    "    for i in range(num_classes):\n",
    "        class_mask = all_labels == i\n",
    "        if class_mask.sum() > 0:\n",
    "            class_correct = (all_predictions[class_mask] == i).sum()\n",
    "            class_total = class_mask.sum()\n",
    "            class_acc = 100 * class_correct / class_total\n",
    "            print(f\"  {class_names[i]}: {class_acc:.2f}% ({class_correct}/{class_total})\")\n",
    "        else:\n",
    "            print(f\"  {class_names[i]}: No samples in test set\")\n",
    "\n",
    "    print(\"Data Distribution Analysis\")\n",
    "\n",
    "    label_counts = Counter(all_labels)\n",
    "    print(\"\\nTest set distribution:\")\n",
    "    for i in range(num_classes):\n",
    "        count = label_counts.get(i, 0)\n",
    "        percentage = 100 * count / len(all_labels) if len(all_labels) > 0 else 0\n",
    "        print(f\"  {class_names[i]}: {count} samples ({percentage:.2f}%)\")\n",
    "\n",
    "    print(\"\\nTraining set distribution:\")\n",
    "    train_label_counts = Counter()\n",
    "    for img_batch, label_batch in train_loader:\n",
    "        train_label_counts.update(label_batch.cpu().numpy())\n",
    "    total_train = sum(train_label_counts.values())\n",
    "    for i in range(num_classes):\n",
    "        count = train_label_counts.get(i, 0)\n",
    "        percentage = 100 * count / total_train if total_train > 0 else 0\n",
    "        print(f\"  {class_names[i]}: {count} samples ({percentage:.2f}%)\")\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"\\nDisplaying all test images with true and predicted labels...\\n\")\n",
    "\n",
    "        # Make sure the model is in eval mode\n",
    "        cls_model.eval()\n",
    "\n",
    "        all_imgs = []\n",
    "        all_true = []\n",
    "        all_pred = []\n",
    "        all_conf = []\n",
    "\n",
    "        cls_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for img_batch, label_batch in test_loader:\n",
    "                img_batch = img_batch.to(device)\n",
    "                label_batch = label_batch.long().to(device)\n",
    "\n",
    "                logits = cls_model(img_batch)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                conf_vals, pred_classes = torch.max(probs, dim=1)\n",
    "\n",
    "                all_imgs.append(img_batch.cpu())\n",
    "                all_true.append(label_batch.cpu())\n",
    "                all_pred.append(pred_classes.cpu())\n",
    "                all_conf.append(conf_vals.cpu())\n",
    "\n",
    "        # Concatenate everything\n",
    "        all_imgs = torch.cat(all_imgs, dim=0)\n",
    "        all_true = torch.cat(all_true, dim=0).numpy()\n",
    "        all_pred = torch.cat(all_pred, dim=0).numpy()\n",
    "        all_conf = torch.cat(all_conf, dim=0).numpy()\n",
    "\n",
    "        sorted_idx = np.argsort(all_conf)\n",
    "\n",
    "        n = all_imgs.shape[0]\n",
    "        def format_img_for_display(img):\n",
    "            if isinstance(img, torch.Tensor):\n",
    "                img = img.cpu()\n",
    "\n",
    "            if img.ndim == 3 and img.shape[0] in [1, 3]:\n",
    "                img = img.permute(1, 2, 0)  # → (H, W, C)\n",
    "            elif img.ndim == 3 and img.shape[2] in [1, 3]:\n",
    "                pass  # already correct\n",
    "            elif img.ndim == 2:\n",
    "                pass  # grayscale OK\n",
    "            elif img.ndim == 3 and img.shape[2] == 1:\n",
    "                img = img.squeeze(2)\n",
    "            elif img.ndim == 3 and img.shape[0] == 1:\n",
    "                img = img.squeeze(0)\n",
    "            else:\n",
    "                while img.ndim > 3:\n",
    "                    img = img.squeeze(0)\n",
    "                if img.ndim == 3 and img.shape[0] not in [1, 3]:\n",
    "                    cdim = img.shape.index(min(img.shape))\n",
    "                    img = img.permute(*(i for i in range(img.ndim) if i != cdim), cdim)\n",
    "\n",
    "            return img.numpy()\n",
    "\n",
    "\n",
    "        for rank, idx in enumerate(sorted_idx):\n",
    "            img = format_img_for_display(all_imgs[idx])\n",
    "            true_label = all_true[idx]\n",
    "            pred_label = all_pred[idx]\n",
    "            conf = all_conf[idx]\n",
    "\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            plt.imshow(img, cmap=\"gray\" if img.ndim == 2 else None)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\n",
    "                f\"Confidence: {conf:.2f}\\n\"\n",
    "                f\"True: {class_names[true_label]}\\n\"\n",
    "                f\"Pred: {class_names[pred_label]}\",\n",
    "                fontsize=10\n",
    "            )\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ab1e609",
   "metadata": {},
   "source": [
    "class FilteredImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, base_dataset, target_class_id):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.target_class_id = target_class_id\n",
    "\n",
    "        self.filtered_indices = []\n",
    "        for idx in range(len(base_dataset)):\n",
    "            _, label = base_dataset[idx]\n",
    "            if isinstance(label, torch.Tensor):\n",
    "                label_value = label.item()\n",
    "            else:\n",
    "                label_value = label\n",
    "\n",
    "            if label_value == target_class_id:\n",
    "                self.filtered_indices.append(idx)\n",
    "\n",
    "        print(\n",
    "            f\"Filtered dataset: {len(self.filtered_indices)} samples for class_id {target_class_id} (vertex count {target_class_id + VERTEX_RANGE[0]})\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filtered_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = self.filtered_indices[idx]\n",
    "        return self.base_dataset[original_idx]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d74d6ae260c9710d",
   "metadata": {},
   "source": [
    "### Polygon Model Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb50bb3b86f806",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "id": "88e8e6cca042c9fd",
   "metadata": {},
   "source": [
    "def train_polygon_model(train_loader, val_loader, poly_model, num_epochs, learning_rate, width, height, verbose=False):\n",
    "    optimizer = torch.optim.Adam(poly_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(\"Starting Polygon Model training...\")\n",
    "    training_start = time.time()\n",
    "\n",
    "    training_loss_history = []\n",
    "    validation_loss_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose:\n",
    "            print(f\"--- Epoch {epoch + 1}/{num_epochs} ---\")\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        if len(train_loader) == 0:\n",
    "            raise Exception(\"No images found in train loader\")\n",
    "\n",
    "        for target_batch, _ in train_loader:  # DataLoader returns (img, label) tuples\n",
    "            target_batch = target_batch.to(device)\n",
    "\n",
    "            loss = poly_train_step(poly_model, target_batch, width, height, optimizer)\n",
    "            epoch_loss += loss\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        training_loss_history.append(avg_epoch_loss)\n",
    "\n",
    "        val_loss = get_poly_val_loss(poly_model, val_loader, width, height)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        validation_loss_history.append(avg_val_loss.item())\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch + 1} Average Validation Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1} Average Training Loss: {avg_epoch_loss:.6f} Time taken {round(time.time() - epoch_start, 2)}\")\n",
    "\n",
    "    clear_cuda_cache()\n",
    "\n",
    "    print(\"Training complete, took \" + str(round(time.time() - training_start, 2)))\n",
    "\n",
    "    return training_loss_history, validation_loss_history"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_polygon_model_all_history(train_loader, val_loader, poly_model, num_epochs, learning_rate, width, height,\n",
    "                                    verbose=False):\n",
    "    optimizer = torch.optim.Adam(poly_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(\"Starting Polygon Model training...\")\n",
    "    training_start = time.time()\n",
    "\n",
    "    training_loss_history = []\n",
    "    validation_loss_history = []\n",
    "    training_accuracy_history = []\n",
    "    validation_accuracy_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose:\n",
    "            print(f\"--- Epoch {epoch + 1}/{num_epochs} ---\")\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        if len(train_loader) == 0:\n",
    "            raise Exception(\"No images found in train loader\")\n",
    "\n",
    "        for target_batch, label_batch in train_loader:\n",
    "            target_batch = target_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "\n",
    "            loss = poly_train_step(poly_model, target_batch, width, height, optimizer)\n",
    "            epoch_loss += loss\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        training_loss_history.append(avg_epoch_loss)\n",
    "\n",
    "        val_loss = get_poly_val_loss(poly_model, val_loader, width, height)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        validation_loss_history.append(avg_val_loss.item())\n",
    "\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for img_batch, label_batch in train_loader:\n",
    "            img_batch = img_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "\n",
    "            pred = poly_model(img_batch)\n",
    "            _, predicted = torch.max(pred, 1)\n",
    "\n",
    "            correct_train += (predicted == label_batch).sum().item()\n",
    "            total_train += label_batch.size(0)\n",
    "\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        for img_batch, label_batch in val_loader:\n",
    "            img_batch = img_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "\n",
    "            pred = poly_model(img_batch)\n",
    "            _, predicted = torch.max(pred, 1)\n",
    "\n",
    "            correct_val += (predicted == label_batch).sum().item()\n",
    "            total_val += label_batch.size(0)\n",
    "\n",
    "        training_accuracy = correct_train / total_train\n",
    "        validation_accuracy = correct_val / total_val\n",
    "\n",
    "        training_accuracy_history.append(training_accuracy)\n",
    "        validation_accuracy_history.append(validation_accuracy)\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Training Loss: {avg_epoch_loss:.6f} - \"\n",
    "                f\"Validation Loss: {avg_val_loss:.6f} - \"\n",
    "                f\"Training Accuracy: {training_accuracy * 100:.2f}% - \"\n",
    "                f\"Validation Accuracy: {validation_accuracy * 100:.2f}% - \"\n",
    "                f\"Time: {round(time.time() - epoch_start, 2)}\"\n",
    "            )\n",
    "\n",
    "    clear_cuda_cache()\n",
    "\n",
    "    print(\"Training complete, took \" + str(round(time.time() - training_start, 2)))\n",
    "\n",
    "    return (\n",
    "        training_loss_history,\n",
    "        validation_loss_history,\n",
    "        training_accuracy_history,\n",
    "        validation_accuracy_history\n",
    "    )\n"
   ],
   "id": "febb2cb2bac47ea8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e5b1bccf",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb789c069ef1fd94",
   "metadata": {},
   "source": [
    "def hp_tuning_trial_polygon(input_shape, num_vertices, num_epochs, trial, width, height, verbose):\n",
    "    class_id = num_vertices - VERTEX_RANGE[0]\n",
    "\n",
    "    filtered_train_dataset = FilteredImageDataset(train_dataset, class_id)\n",
    "    filtered_val_dataset = FilteredImageDataset(val_dataset, class_id)\n",
    "\n",
    "    filtered_train_loader = DataLoader(\n",
    "        filtered_train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        worker_init_fn=seed_worker\n",
    "    )\n",
    "\n",
    "    filtered_val_loader = DataLoader(\n",
    "        filtered_val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        worker_init_fn=seed_worker\n",
    "    )\n",
    "\n",
    "    model = create_poly_model(input_shape, num_vertices,\n",
    "                              conv_filters=trial[\"conv_filters\"],\n",
    "                              dropout_rate=trial[\"dropout_rate\"],\n",
    "                              activation=trial[\"activation\"]\n",
    "                              )\n",
    "    model.to(device)\n",
    "\n",
    "    try:\n",
    "        training_loss_history, validation_loss_history = train_polygon_model(\n",
    "            filtered_train_loader,\n",
    "            filtered_val_loader,\n",
    "            model,\n",
    "            num_epochs=num_epochs,\n",
    "            learning_rate=trial[\"learning_rate\"],\n",
    "            width=width,\n",
    "            height=height,\n",
    "            verbose=verbose\n",
    "        )\n",
    "    finally:\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        clear_cuda_cache()\n",
    "\n",
    "    return validation_loss_history\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d1e1ea58c8f5fa6e",
   "metadata": {},
   "source": [
    "def run_polygon_hp_tuning(tuning_results_folder, parameter_grid, num_epochs, num_vertices, verbose):\n",
    "    input_shape = (width, height, 1)\n",
    "\n",
    "    if num_vertices != POLYGON_VERTICES:\n",
    "        raise ValueError(\n",
    "            f\"Mismatch: num_vertices parameter ({num_vertices}) does not match POLYGON_VERTICES ({POLYGON_VERTICES})\")\n",
    "\n",
    "    polygon_tuning_results_folder = os.path.join(tuning_results_folder, f'polygon_{num_vertices}')\n",
    "    os.makedirs(polygon_tuning_results_folder, exist_ok=True)\n",
    "\n",
    "    initial_trial_index = 0\n",
    "\n",
    "    if CONTINUE_LAST_RUN:\n",
    "        # look in the folder, and find the most recent file\n",
    "        results_files = glob.glob(\n",
    "            os.path.join(polygon_tuning_results_folder, f\"time_polygon_{num_vertices}_hp_tuning_results_*.json\"))\n",
    "        if len(results_files) != 0:\n",
    "            results_file = os.path.basename(max(results_files, key=os.path.getctime))\n",
    "            with open(os.path.join(polygon_tuning_results_folder, results_file), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                # check if vertex number matches\n",
    "                if 'meta' in data and 'num_vertices' in data['meta']:\n",
    "                    stored_vertices = data['meta']['num_vertices']\n",
    "                    if stored_vertices != num_vertices:\n",
    "                        raise ValueError(\n",
    "                            f\"Vertex number mismatch: JSON file has {stored_vertices} vertices but current run specifies {num_vertices} vertices.\")\n",
    "\n",
    "                completed_trials = data['meta'][\"completed_trials\"]\n",
    "                total_trials = data['meta'][\"total_trials\"]\n",
    "\n",
    "                if completed_trials >= total_trials:\n",
    "                    print(f\"All {total_trials} trials already completed in {results_file}. Starting new tuning run.\")\n",
    "                elif total_trials != NUM_TRIALS:\n",
    "                    print(\n",
    "                        f\"Warning: Mismatch in total trials. Previous run had {total_trials} trials, current run has {NUM_TRIALS} trials. Starting new tuning run.\")\n",
    "                else:\n",
    "                    initial_trial_index = completed_trials\n",
    "                    print(f\"Continuing from last run, starting with trial_index = {initial_trial_index}\")\n",
    "\n",
    "    for trial_index in range(initial_trial_index, NUM_TRIALS):\n",
    "        print(f\"\\n=== Hyperparameter Tuning Trial {trial_index + 1}/{NUM_TRIALS} for {num_vertices} vertices ===\")\n",
    "\n",
    "        if trial_index == 0:\n",
    "            job_id_suffix = f\"job{SLURM_JOB_ID}_\" if SLURM_JOB_ID else \"\"\n",
    "            results_file = f\"time_polygon_{num_vertices}_hp_tuning_results_\" + job_id_suffix + time.strftime(\n",
    "                \"%Y%m%d-%H%M%S\") + \".json\"\n",
    "            data = {\n",
    "                \"meta\": {\n",
    "                    \"total_trials\": NUM_TRIALS,\n",
    "                    \"completed_trials\": 0,\n",
    "                    \"num_vertices\": num_vertices\n",
    "                },\n",
    "                \"results\": []\n",
    "            }\n",
    "            with open(os.path.join(polygon_tuning_results_folder, results_file), 'w') as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "        else:\n",
    "            # look in the folder, and find the most recent file\n",
    "            results_files = glob.glob(\n",
    "                os.path.join(polygon_tuning_results_folder, f\"time_polygon_{num_vertices}_hp_tuning_results_*.json\"))\n",
    "            if len(results_files) == 0:\n",
    "                raise Exception(f\"No results file found in {polygon_tuning_results_folder}. Expected one from trial 0.\")\n",
    "            results_file = os.path.basename(max(results_files, key=os.path.getctime))\n",
    "\n",
    "        # randomly sample hyperparameters from parameter grid\n",
    "        trial = {\n",
    "            'learning_rate': random.choice(parameter_grid['learning_rate']),\n",
    "            'conv_filters': random.choice(parameter_grid['conv_filters']),\n",
    "            'dropout_rate': random.choice(parameter_grid['dropout_rate']),\n",
    "            'activation': random.choice(parameter_grid['activation']),\n",
    "        }\n",
    "        print(f\"Trial {trial_index + 1} hyperparameters: {trial}\")\n",
    "\n",
    "        val_loss_history = hp_tuning_trial_polygon(input_shape, num_vertices, num_epochs, trial, width, height, verbose)\n",
    "\n",
    "        best_val_loss = min(val_loss_history)\n",
    "        best_val_loss_epoch = val_loss_history.index(best_val_loss) + 1\n",
    "\n",
    "        with open(os.path.join(polygon_tuning_results_folder, results_file), 'r+') as f:\n",
    "            data = json.load(f)\n",
    "            data[\"meta\"][\"completed_trials\"] = trial_index + 1\n",
    "            data[\"results\"].append({\n",
    "                'trial_index': trial_index + 1,\n",
    "                'hyperparameters': trial,\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_epoch': best_val_loss_epoch,\n",
    "            })\n",
    "            f.seek(0)\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "        print(f\"Trial {trial_index + 1} best validation loss: {best_val_loss:.6f} at epoch {best_val_loss_epoch}\")\n",
    "\n",
    "        print_gpu_memory()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "46e2d6bb447f301c",
   "metadata": {},
   "source": [
    "if args.model == 'polygon':\n",
    "    if POLYGON_VERTICES is not None:\n",
    "        run_polygon_hp_tuning(TUNING_RESULTS_FOLDER, POLYGON_PARAMETER_GRID, NUM_EPOCHS, POLYGON_VERTICES, VERBOSE)\n",
    "    else:\n",
    "        print(\"Skipping polygon hyperparameter tuning: --num-vertices not specified\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "47a1765a",
   "metadata": {},
   "source": [
    "#### Train Polygon Model with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "id": "8d8b25f2636d31cb",
   "metadata": {},
   "source": [
    "if args.model == 'polygon':\n",
    "    if POLYGON_VERTICES is None:\n",
    "        raise ValueError(\n",
    "            \"--num-vertices argument is required for polygon model training. Please specify it when running the notebook.\")\n",
    "\n",
    "    num_vertices = POLYGON_VERTICES\n",
    "    class_id = num_vertices - VERTEX_RANGE[0]\n",
    "\n",
    "    # find json file with tuning results, most recent that is completed\n",
    "    polygon_tuning_results_folder = os.path.join(TUNING_RESULTS_FOLDER, f'polygon_{num_vertices}')\n",
    "    results_files = glob.glob(\n",
    "        os.path.join(polygon_tuning_results_folder, f\"time_polygon_{num_vertices}_hp_tuning_results_*.json\"))\n",
    "    if len(results_files) == 0:\n",
    "        raise Exception(f\"No tuning results file found in {polygon_tuning_results_folder}\")\n",
    "\n",
    "    results_file = os.path.basename(max(results_files, key=os.path.getctime))\n",
    "\n",
    "    best_hyperparameters = best_epoch = None\n",
    "    with open(os.path.join(polygon_tuning_results_folder, results_file), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        # Verify vertex number matches\n",
    "        if 'meta' in data and 'num_vertices' in data['meta']:\n",
    "            stored_vertices = data['meta']['num_vertices']\n",
    "            if stored_vertices != num_vertices:\n",
    "                raise ValueError(\n",
    "                    f\"Vertex number mismatch: JSON file has {stored_vertices} vertices but current run specifies {num_vertices} vertices.\")\n",
    "\n",
    "        completed_trials = data['meta'][\"completed_trials\"]\n",
    "        total_trials = data['meta'][\"total_trials\"]\n",
    "        if completed_trials < total_trials:\n",
    "            print(\n",
    "                f\"Warning: Tuning run in {results_file} not complete. Completed {completed_trials}/{total_trials} trials. Please complete tuning or delete incomplete tuning file\")\n",
    "\n",
    "        results = data['results']\n",
    "        best_trial = sorted(results, key=lambda x: x['best_val_loss'])[0]\n",
    "        best_hyperparameters = best_trial['hyperparameters']\n",
    "        best_epoch = best_trial['best_epoch']\n",
    "\n",
    "    if best_hyperparameters is None or best_epoch is None:\n",
    "        raise Exception(f\"Could not find best hyperparameters or best epoch in {results_file}\")\n",
    "\n",
    "    print(f\"Best hyperparameters from tuning in {results_file}:\")\n",
    "    for k, v in best_hyperparameters.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    print(f\"Best epoch from tuning: {best_epoch}\")\n",
    "\n",
    "    filtered_train_dataset = FilteredImageDataset(train_dataset, class_id)\n",
    "    filtered_val_dataset = FilteredImageDataset(val_dataset, class_id)\n",
    "\n",
    "    filtered_train_loader = DataLoader(\n",
    "        filtered_train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        worker_init_fn=seed_worker\n",
    "    )\n",
    "\n",
    "    filtered_val_loader = DataLoader(\n",
    "        filtered_val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        worker_init_fn=seed_worker\n",
    "    )\n",
    "\n",
    "    poly_model = create_poly_model(\n",
    "        input_shape,\n",
    "        num_vertices,\n",
    "        conv_filters=best_hyperparameters['conv_filters'],\n",
    "        dropout_rate=best_hyperparameters['dropout_rate'],\n",
    "        activation=best_hyperparameters['activation']\n",
    "    )\n",
    "\n",
    "    poly_model.to(device)\n",
    "\n",
    "    training_loss_history, validation_loss_history = train_polygon_model(\n",
    "        filtered_train_loader,\n",
    "        filtered_val_loader,\n",
    "        poly_model,\n",
    "        num_epochs=best_epoch,\n",
    "        learning_rate=best_hyperparameters['learning_rate'],\n",
    "        width=width,\n",
    "        height=height,\n",
    "        verbose=True\n",
    "    )\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "58d44cfb",
   "metadata": {},
   "source": [
    "#### Save model\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6636d3e7",
   "metadata": {},
   "source": [
    "if args.model == 'polygon':\n",
    "    torch.save({\n",
    "        \"model_state\": poly_model.state_dict(),\n",
    "        \"hyperparameters\": best_hyperparameters,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"num_vertices\": num_vertices,\n",
    "    }, POLYGON_MODEL_SAVE_PATH_LAMBDA(num_vertices))\n",
    "\n",
    "    print(f\"Saved model to {POLYGON_MODEL_SAVE_PATH_LAMBDA(num_vertices)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7a4aca73",
   "metadata": {},
   "source": [
    "#### Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1cb8ed9d1e7df4ce",
   "metadata": {},
   "source": [
    "if args.model == 'polygon':\n",
    "    if POLYGON_VERTICES is None:\n",
    "        raise ValueError(\n",
    "            \"--num-vertices argument is required for polygon model training. Please specify it when running the notebook.\")\n",
    "\n",
    "    num_vertices = POLYGON_VERTICES\n",
    "\n",
    "    loaded = torch.load(POLYGON_MODEL_SAVE_PATH_LAMBDA(num_vertices), map_location=device)\n",
    "\n",
    "    if 'num_vertices' in loaded:\n",
    "        if loaded['num_vertices'] != num_vertices:\n",
    "            raise ValueError(\n",
    "                f\"Vertex number mismatch: Model file has {loaded['num_vertices']} vertices but current run specifies {num_vertices} vertices.\")\n",
    "\n",
    "    loaded_hparams = loaded[\"hyperparameters\"]\n",
    "    loaded_num_vertices = loaded.get(\"num_vertices\", num_vertices)\n",
    "\n",
    "    try:\n",
    "        model_loaded = create_poly_model(\n",
    "            input_shape,\n",
    "            loaded_num_vertices,\n",
    "            conv_filters=loaded_hparams[\"conv_filters\"],\n",
    "            dropout_rate=loaded_hparams[\"dropout_rate\"],\n",
    "            activation=loaded_hparams[\"activation\"],\n",
    "        )\n",
    "\n",
    "        model_loaded.load_state_dict(loaded[\"model_state\"])\n",
    "        model_loaded.to(device)\n",
    "        model_loaded.eval()\n",
    "\n",
    "        print(\"Model loaded and ready.\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error loading model\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4721d2cf",
   "metadata": {},
   "source": [
    "#### Evaluate Polygon on Test Set\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRYING TO FIX CLASSIFIER MODEL\n",
    "\n",
    "if DEBUG and args.model == 'polygon':\n",
    "    best_hyperparameters = {\n",
    "        'learning_rate': 0.0001,\n",
    "        'conv_filters': [32, 48, 48, 64],\n",
    "        'dense_units': 64,\n",
    "        'dropout_rate': 0,\n",
    "        'activation': 'relu',\n",
    "        'patience': 25,\n",
    "        'best_epoch': None,\n",
    "    }\n",
    "    # best_epoch = 177\n",
    "\n",
    "    results_file_3 = \"output/tuning_results_v2/polygon_3/time_polygon_3_hp_tuning_results_job2682_20251128-145124.json\"\n",
    "    results_file_4 = \"output/tuning_results_v2/polygon_4/time_polygon_4_hp_tuning_results_job2683_20251128-145133.json\"\n",
    "    results_file_5 = \"output/tuning_results_v2/polygon_5/time_polygon_5_hp_tuning_results_job2684_20251128-145517.json\"\n",
    "    results_file_6 = \"output/tuning_results_v2/polygon_6/time_polygon_6_hp_tuning_results_job2687_20251128-150000.json\"\n",
    "\n",
    "    poly_hp = {3: {}, 4: {}, 5: {}, 6: {}}\n",
    "\n",
    "    file_map = {\n",
    "        results_file_3: 3,\n",
    "        results_file_4: 4,\n",
    "        results_file_5: 5,\n",
    "        results_file_6: 6\n",
    "    }\n",
    "\n",
    "    for each in [results_file_3, results_file_4, results_file_5, results_file_6]:\n",
    "        with open(each, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        best = min(data[\"results\"], key=lambda x: x[\"best_val_loss\"])\n",
    "\n",
    "        # Start with base defaults\n",
    "        merged = dict(best_hyperparameters)\n",
    "\n",
    "        # Overwrite with values from best trial\n",
    "        for k, v in best[\"hyperparameters\"].items():\n",
    "            merged[k] = v\n",
    "\n",
    "        merged['best_epoch'] = best['best_epoch']\n",
    "\n",
    "        # Store result\n",
    "        poly_hp[file_map[each]] = merged\n",
    "\n",
    "        print()\n",
    "        print(\"Best trial_id:\", best[\"trial_index\"])\n",
    "        print(\"Best val_loss:\", best[\"best_val_loss\"])\n",
    "        print(\"Best epoch:\", best[\"best_epoch\"])\n",
    "        print(\"Merged hyperparameters:\")\n",
    "        print(merged)"
   ],
   "id": "f9692ead22e684ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# if DEBUG and args.model == 'polygon':\n",
    "#     poly_models = {3: None, 4: None, 5: None, 6: None}\n",
    "#     poly_models_training_history = {3: {'train_loss': [], 'val_loss': []},\n",
    "#                                     4: {'train_loss': [], 'val_loss': []},\n",
    "#                                     5: {'train_loss': [], 'val_loss': []},\n",
    "#                                     6: {'train_loss': [], 'val_loss': []},\n",
    "#                                     }\n",
    "#\n",
    "#     for each in poly_models:\n",
    "#         set_seeds()\n",
    "#         poly_model = PolygonCNN(input_shape,\n",
    "#                                each,\n",
    "#                                conv_filters=poly_hp[each]['conv_filters'],\n",
    "#                                dense_units=poly_hp[each]['dense_units'],\n",
    "#                                dropout_rate=poly_hp[each]['dropout_rate'],\n",
    "#                                activation=poly_hp[each]['activation']\n",
    "#                                )\n",
    "#\n",
    "#         best_epoch = poly_hp[each]['best_epoch']\n",
    "#\n",
    "#         poly_model.to(device)\n",
    "#         training_loss_history, validation_loss_history = train_polygon_model(\n",
    "#             train_loader,\n",
    "#             val_loader,\n",
    "#             poly_model,\n",
    "#             num_epochs=best_epoch,\n",
    "#             learning_rate=best_hyperparameters['learning_rate'],\n",
    "#             width=width,\n",
    "#             height=height,\n",
    "#             verbose=True\n",
    "#         )\n",
    "#\n",
    "#         poly_models[each] = poly_model\n",
    "#         poly_models_training_history[each]['train_loss'] = training_loss_history\n",
    "#         poly_models_training_history[each]['val_loss'] = validation_loss_history"
   ],
   "id": "18711c3ff351dd6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MODEL_SAVE_DIR = \"models/polygon\"\n",
    "\n",
    "poly_models_training_history = {3: {'train_loss': [], 'val_loss': []},\n",
    "                                4: {'train_loss': [], 'val_loss': []},\n",
    "                                5: {'train_loss': [], 'val_loss': []},\n",
    "                                6: {'train_loss': [], 'val_loss': []},\n",
    "                                }\n",
    "\n",
    "for each in poly_models_training_history:\n",
    "    NUM_VERTICES = each\n",
    "\n",
    "    model_path = os.path.join(MODEL_SAVE_DIR, f\"polygon_{NUM_VERTICES}_model.pth\")\n",
    "\n",
    "    checkpoint = torch.load(model_path)\n",
    "\n",
    "    print(f\"Successfully loaded model checkpoint from: {model_path}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 2. Extract the loss histories\n",
    "    training_loss = checkpoint.get(\"training_loss\")\n",
    "    validation_loss = checkpoint.get(\"validation_loss\")\n",
    "\n",
    "    poly_models_training_history[each]['train_loss'] = training_loss\n",
    "    poly_models_training_history[each]['val_loss'] = validation_loss\n",
    "\n",
    "output_path = \"plot_data/polygon_training_history.json\"\n",
    "\n",
    "serializable_history = {}\n",
    "\n",
    "for k, v in poly_models_training_history.items():\n",
    "    serializable_history[k] = {\n",
    "        \"train_loss\": [float(x) for x in v['train_loss']],\n",
    "        \"val_loss\": [float(x) for x in v['val_loss']],\n",
    "    }\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(serializable_history, f, indent=4)\n",
    "\n",
    "print(f\"Saved training history to {output_path}\")\n"
   ],
   "id": "7d9c088a358db469",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if DEBUG and args.model == 'polygon':\n",
    "    os.makedirs(\"plot_data/polygon\", exist_ok=True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    colors = {\n",
    "        3: 'tab:blue',\n",
    "        4: 'tab:orange',\n",
    "        5: 'tab:green',\n",
    "        6: 'tab:red'\n",
    "    }\n",
    "\n",
    "    combined_output = {}\n",
    "\n",
    "    for num_vertices in [3, 4, 5, 6]:\n",
    "        hist = poly_models_training_history[num_vertices]\n",
    "        train_loss = hist['train_loss']\n",
    "        val_loss = hist['val_loss']\n",
    "\n",
    "        ax.plot(\n",
    "            train_loss,\n",
    "            color=colors[num_vertices],\n",
    "            linestyle='-',\n",
    "            label=f'{num_vertices}-Vertex Train'\n",
    "        )\n",
    "\n",
    "        ax.plot(\n",
    "            val_loss,\n",
    "            color=colors[num_vertices],\n",
    "            linestyle='--',\n",
    "            label=f'{num_vertices}-Vertex Val'\n",
    "        )\n",
    "\n",
    "        combined_output[num_vertices] = {\n",
    "            \"training_loss\": train_loss,\n",
    "            \"validation_loss\": val_loss,\n",
    "        }\n",
    "\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Polygon Models (3–6 Vertices): Training vs Validation Loss')\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(\"plot_data/polygon_models_training_plot.svg\", format=\"svg\")\n",
    "    fig.savefig(\"plot_data/polygon_models_training_plot.pdf\", format=\"pdf\")\n",
    "    fig.savefig(\"plot_data/polygon_models_training_plot.png\", format=\"png\")\n",
    "\n",
    "    # Save combined JSON dataset for full plot\n",
    "    json_path = \"plot_data/polygon/polygon_all_training_curves.json\"\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(combined_output, f, indent=4)\n",
    "\n",
    "    print(f\"Saved combined plot data to: {json_path}\")\n"
   ],
   "id": "d6140b83aeab99fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b113f412f2e6c6",
   "metadata": {},
   "source": [
    "if args.model == 'polygon':\n",
    "    if POLYGON_VERTICES is None:\n",
    "        raise ValueError(\n",
    "            \"--num-vertices argument is required for polygon model training. Please specify it when running the notebook.\")\n",
    "\n",
    "    num_vertices = POLYGON_VERTICES\n",
    "    class_id = num_vertices - VERTEX_RANGE[0]\n",
    "\n",
    "    filtered_test_dataset = FilteredImageDataset(test_dataset, class_id)\n",
    "\n",
    "    filtered_test_loader = DataLoader(\n",
    "        filtered_test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        worker_init_fn=seed_worker\n",
    "    )\n",
    "\n",
    "    poly_model.eval()\n",
    "    test_loss = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    print(f\"Evaluating polygon model ({num_vertices} vertices) on test set...\")\n",
    "    with torch.no_grad():\n",
    "        for target_batch, _ in filtered_test_loader:\n",
    "            target_batch = target_batch.to(device)\n",
    "            coord_pred_batch = poly_model(target_batch)\n",
    "            batch_size = target_batch.shape[0]\n",
    "            batch_loss = 0.0\n",
    "            for i in range(batch_size):\n",
    "                target_img = target_batch[i]\n",
    "                coord_pred = coord_pred_batch[i]\n",
    "                pred_img = rasterize(coord_pred, width=width, height=height)\n",
    "                loss = torch.mean((pred_img - target_img) ** 2)\n",
    "                batch_loss += loss\n",
    "            test_loss += batch_loss / batch_size\n",
    "            num_samples += batch_size\n",
    "\n",
    "    # Calculate average test loss\n",
    "    avg_test_loss = test_loss / len(filtered_test_loader)\n",
    "\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"Polygon Model ({num_vertices} vertices) Test Set Evaluation Results\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    print(f\"Average Test Loss: {avg_test_loss:.6f}\")\n",
    "    print(f\"Number of test samples: {num_samples}\")\n",
    "    print(f\"{'=' * 50}\\n\")\n",
    "\n",
    "    print(\"Visualizing sample predictions...\")\n",
    "    poly_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for target_batch, _ in filtered_test_loader:\n",
    "            target_batch = target_batch.to(device)\n",
    "            coord_pred_batch = poly_model(target_batch)\n",
    "\n",
    "            num_show = min(3, target_batch.shape[0])\n",
    "            for i in range(num_show):\n",
    "                coord_pred = coord_pred_batch[i]\n",
    "                pred_img = rasterize(coord_pred, width=width, height=height)\n",
    "                loss = torch.mean((pred_img - target_batch[i]) ** 2)\n",
    "\n",
    "                target_np = target_batch[i].cpu().detach().squeeze(-1).numpy()\n",
    "                pred_np = pred_img.cpu().detach().squeeze(-1).numpy()\n",
    "\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "                axes[0].imshow(target_np, cmap='gray')\n",
    "                axes[0].set_title('Target')\n",
    "                axes[0].axis('off')\n",
    "\n",
    "                axes[1].imshow(pred_np, cmap='gray')\n",
    "                axes[1].set_title(f'Predicted (Loss: {loss.item():.4f})')\n",
    "                axes[1].axis('off')\n",
    "\n",
    "                axes[2].set_title('SVG Coordinates')\n",
    "                points_np = coord_pred.detach().cpu().numpy()\n",
    "                points_scaled = points_np * 64\n",
    "\n",
    "                polygon = patches.Polygon(points_scaled, closed=True,\n",
    "                                          edgecolor='black', facecolor='black',\n",
    "                                          linewidth=0)\n",
    "                axes[2].set_xlim(0, 64)\n",
    "                axes[2].set_ylim(0, 64)\n",
    "                axes[2].invert_yaxis()\n",
    "                axes[2].set_aspect('equal')\n",
    "                axes[2].set_facecolor('white')\n",
    "                axes[2].add_patch(polygon)\n",
    "                axes[2].axis('off')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            break"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7d68f276a27e002f",
   "metadata": {},
   "source": "### Evaluation with tuned models"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Classifier",
   "id": "5332704c6d4ce3f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if DEBUG and args.model == 'classifier':\n",
    "    results_file = \"output/tuning_results_v2/classifier/time_classifier_hp_tuning_results_job2678_20251128-113516.json\"\n",
    "\n",
    "    with open(results_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(\"Number of trials:\", len(data[\"results\"]))\n",
    "\n",
    "    best = min(data[\"results\"], key=lambda x: x[\"best_val_loss\"])\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Best trial_id:\", best[\"trial_index\"])\n",
    "    print(\"Best val_accuracy:\", best[\"best_val_loss\"])\n",
    "    print(\"Hyperparameters:\", best[\"hyperparameters\"])\n",
    "    print(\"Best epoch:\", best[\"best_epoch\"])\n",
    "\n",
    "    best_hyperparameters = best[\"hyperparameters\"]\n",
    "    best_epoch = best[\"best_epoch\"]"
   ],
   "id": "ec88961ee74ae941",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if DEBUG and args.model == 'classifier':\n",
    "    set_seeds()\n",
    "    cls_model = ClassifierCNN(input_shape,\n",
    "                              num_classes,\n",
    "                              conv_filters=best_hyperparameters[\"conv_filters\"],\n",
    "                              dense_units=best_hyperparameters[\"dense_units\"],\n",
    "                              dropout2d_rate_CNN=0,\n",
    "                              dropout_rate_FFN=best_hyperparameters[\"dropout_rate\"],\n",
    "                              activation=best_hyperparameters[\"activation\"],\n",
    "                              batch_norm=0\n",
    "                              )\n",
    "\n",
    "    cls_model.to(device)\n",
    "    training_loss_history, validation_loss_history, training_accuracy_history, validation_accuracy_history = train_classifier_model(\n",
    "        train_loader,\n",
    "        cls_model,\n",
    "        num_epochs=best_epoch,\n",
    "        learning_rate=best_hyperparameters['learning_rate'],\n",
    "        weight_decay=best_hyperparameters[\"weight_decay\"],\n",
    "        patience=best_hyperparameters[\"patience\"],\n",
    "        verbose=True\n",
    "    )"
   ],
   "id": "cad99df4311c27a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Polygons",
   "id": "aca6af31ba890cd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if DEBUG and args.model == 'polygon':\n",
    "    results_file = \"output/tuning_results_v2/polygon_3/time_polygon_3_hp_tuning_results_job2682_20251128-145124.json\"\n",
    "\n",
    "    with open(results_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(\"Number of trials:\", len(data[\"results\"]))\n",
    "    print(\"Number of vertices:\", data[\"meta\"][\"num_vertices\"])\n",
    "\n",
    "    best = min(data[\"results\"], key=lambda x: x[\"best_val_loss\"])\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Best trial_id:\", best[\"trial_index\"])\n",
    "    print(\"Best val_accuracy:\", best[\"best_val_loss\"])\n",
    "    print(\"Hyperparameters:\", best[\"hyperparameters\"])\n",
    "    print(\"Best epoch:\", best[\"best_epoch\"])\n",
    "\n",
    "    best_hyperparameters = best[\"hyperparameters\"]\n",
    "    best_epoch = best[\"best_epoch\"]"
   ],
   "id": "3da28741a0f9256b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
